# -*- coding: utf-8 -*-
"""VAD_v8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qknINFXvAYRFIJFC133u3XKLspooCm9Y
"""

!pip install pydub

!pip install -U -q PyDrive

#Required packages of google colab setup

import os
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

## Authenticating this notebook to access google drive
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

## Mount google drive file system and make it available to read and write
from google.colab import drive
drive.mount('/content/drive')

"""## Voice Activity Detection in noisy environment"""

import os
import numpy as np
from pydub import AudioSegment
from matplotlib import pyplot as plt

## Plot the spe
def spectrum_plot(signal, fs = 44100, title = "Title"):
  plt.figure(figsize = (15,5))
  plt.magnitude_spectrum(signal,Fs= fs)
  plt.title(title)
  plt.show()
  pass
  
## Normalize the signal 
def normalize(signal):
  abs_peak = np.amax(np.abs(signal))
  return signal * (1/abs_peak)

## List the audio files in the folder 
## Point this address to your folder that contains all the audio files
audio_samples = os.listdir("drive/My Drive/Colab_Notebooks/Audio_files/Samples")
len(audio_samples)

import random

random.seed(234)

## Randomize the audio file names
random.shuffle(audio_samples)

## Pick the top N to append one after the other
audio_samples = audio_samples[0:500]

## Read wav files from the location specified above
sound1 = AudioSegment.from_wav("drive/My Drive/Colab_Notebooks/Audio_files/Samples/" + audio_samples[50])

for index in range(1,len(audio_samples)):
    sound2 = AudioSegment.from_wav("drive/My Drive/Colab_Notebooks/Audio_files/Samples/" + audio_samples[index])
    sound1 += sound2
    pass

## Save the merged signal to the working directory
sound1.export("sound1.wav",format = "wav")

## Load back using Librosa 
import librosa
speech_signal, fs = librosa.load("sound1.wav")
speech_signal = normalize(speech_signal)

## Sample plot of the speech signal
plt.figure(1)
plt.title('Speech')
plt.plot(speech_signal[22050:44100])
plt.show()

## Spectrum plot of the signal with hamming window
spectrum_plot(np.hamming(22050) * speech_signal[22050:44100])

## Preemphasis of the signal
emphasized_signal = np.append(speech_signal[0], speech_signal[1:] - 0.97 * speech_signal[:-1])

## Plot of speech signal after pre-emphasis
plt.figure(1)
plt.title('Speech')
plt.plot(emphasized_signal[22050:44100])
plt.show()

## Spectrum plot of Emphasized signal
spectrum_plot(np.hamming(22050) * emphasized_signal[22050:44100])

frame_size = int(0.1 * 22050) ## 100 ms per frame
centroids = librosa.feature.spectral_centroid(emphasized_signal,sr = fs,hop_length=frame_size)[0]  ##

"""## Create Mask signal"""

index1 = 0
centroid_index = 0
mask = np.array([],dtype="int")
speech_median = np.median(np.abs(emphasized_signal)) ## Median energy of the signal

for index2 in range(int(0.1*22050),len(emphasized_signal),frame_size):
  ## Use Median energy and frequency centroid of the signal to calculate the mask signal 
  mask1 = 1 * ((np.abs(emphasized_signal[index1:index2])>= speech_median) & (centroids[centroid_index] <=7500))
  mask = np.append(mask, mask1)

  index1 = index2
  print(index1,end="\r")
  pass

## Running mean 

def running_mean(x, N):
    cumsum = np.cumsum(np.insert(x, 0, 0)) 
    return (cumsum[N:] - cumsum[:-N]) / float(N)

mask_len = len(mask)

#1500 point moving average 
smooth_mask = np.round(running_mean(mask,1500))

#100 point left shift to adjust for the late rise of the moving average
#smooth_mask = smooth_mask[100:len(smooth_mask)]

#Zero padding at the end
smooth_mask = np.concatenate((smooth_mask, np.zeros((len(mask) - len(smooth_mask)))))

length = len(smooth_mask)

## Adjust for the moving average
smooth_mask = np.concatenate([[0] * 800, smooth_mask])[0:length]

## Masking signal plot
plt.figure(figsize=(15,5))
plt.figure(1)
plt.title('Mask signal identifying speech parts of the signal')
plt.plot(smooth_mask[0:44100])
plt.show()

## Actual Signal
plt.figure(figsize=(15,5))
plt.figure(1)
plt.title('Speech')
plt.plot(emphasized_signal[0:44100])
plt.show()

"""## Local normalization of the signal for every 1 sec"""

index1 = 0
for index2 in range(22050,len(emphasized_signal),22050):
  emphasized_signal[index1:index2] = normalize(emphasized_signal[index1:index2])
  index1 = index2
  print(index1,end="\r")
  pass

## Write the emphasized signal to the working directory
librosa.output.write_wav("emphasized_speech.wav",np.float32(emphasized_signal),fs)

"""## Add Noise"""

## Load the noise signal from the location
noise_signal, fs = librosa.load("drive/My Drive/Colab_Notebooks/Audio_files/background_noise/exercise_bike.wav")

for i in range(0,25):
    noise_signal = np.concatenate((noise_signal,noise_signal))
    if(len(noise_signal)> len(emphasized_signal)):
        noise_signal = noise_signal[0:len(emphasized_signal)]
        break
        
noise_signal[noise_signal ==0] = 0.0001
SNR = -10
noise = 10**(-SNR/20)* normalize(noise_signal)

plt.figure(1,figsize= (15,5))
plt.title('Noise')
plt.plot(normalize(noise[0:500000]))
plt.show()

## Add noise to the signal
signal_w_noise = normalize(emphasized_signal + normalize(noise))

## Overlay mask on signal with noise
plt.figure(1,figsize= (15,5))
plt.title('Speech')
plt.plot(signal_w_noise[0:50000])
plt.plot(smooth_mask[0:50000],color = "red")
plt.show()

librosa.output.write_wav("drive/My Drive/Colab_Notebooks/emphasised_with_noise_-10.wav",np.float32(signal_w_noise),fs)

"""## Train test split"""

## Training data split

signal_train = signal_w_noise[0:round(len(smooth_mask)* 0.7)]
signal_valid = signal_w_noise[round(len(smooth_mask)* 0.7): len(smooth_mask)]

## Validation data split

smooth_mask_train = smooth_mask[0:round(len(smooth_mask)* 0.7)]
smooth_mask_valid = smooth_mask[round(len(smooth_mask)* 0.7): len(smooth_mask)]

"""## Audio to Image"""

## Convert audio to image

import cv2
def audio_to_image(signal, height=192, width=192):
  hl = signal.shape[0]//(width*1.1)
  spec = np.abs(librosa.stft(signal,n_fft = 1024 ,hop_length = int(hl),window = "hann",win_length = height))   # STFT with hanning window
  img = librosa.amplitude_to_db(spec) **2
  img = cv2.resize(img, dsize=(height, width))  # Reshape image to fixed size
  img = img.reshape(height,width,1) 
  img = (img - np.min(img))/(np.max(img) - np.min(img)) # Image normalization using min max normalization technique
  return img

## Sample image file from audio
img1 = audio_to_image(signal_train[10000:23000],height=256,width=256)
img1.shape

plt.imshow(img1[:,:,0])

## Preprocessing of the speech signal with noise

def signal_preprocessing(signal, smooth_mask, frame_size, img_height,img_width):
  #frame_overlap = int(frame_size * frame_overlap) # half frame overlap

  index1 = 0
  temp = 1
  
  ## Calulate average and round the mask for the the given frame
  mask = [int(np.round(np.mean(smooth_mask[0:frame_size])))]
  
  # Audio to image conversion
  features = audio_to_image(signal[index1:frame_size],height= img_width,width= img_width)

  for index2 in range(frame_size,len(signal),frame_size):
      #index2 += frame_size
      if(index2> len(signal)):
          break
      print(index1,index2,end = "\r")
      
      x = [int(np.round(np.mean(smooth_mask[index1:index2])))]

      f1 = audio_to_image(signal[index1:index2],height= img_height,width= img_width)    

      if temp == 1:
          mask = np.concatenate([[mask],[x]])
          features = np.concatenate([[features],[f1]])
          temp = 0
          pass
      else:
          mask = np.concatenate([mask,[x]])
          features = np.concatenate([features,[f1]])
          pass
      index1 = index2
      pass
  return features, mask

## Training dataset creation
features_train, mask_train = signal_preprocessing(signal = signal_train, smooth_mask = smooth_mask_train, frame_size = int(0.1 * 22050), img_height = 100,img_width = 100)

## Validation dataset creation
features_valid, mask_valid = signal_preprocessing(signal = signal_valid, smooth_mask = smooth_mask_valid, frame_size = int(0.1 * 22050), img_height = 100,img_width = 100)

librosa.output.write_wav("drive/My Drive/Colab_Notebooks/signal_valid.wav",np.float32(signal_valid),fs)

"""## Model"""

## Import required library for Keras CNN implementation
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.callbacks import TensorBoard, EarlyStopping
from tensorflow.keras.utils import to_categorical
import pickle
import time

NAME = "CNN_Model_spectrum_image"

np.random.seed(23)

## Sequential model implementation
model = Sequential()
 
## Convolutional layer 
model.add(Conv2D(150, (4, 4), input_shape=(100,100,1),padding = "same"))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.3))
 
#model.add(Conv2D(128, (4, 4)))
#model.add(Activation('relu'))
#model.add(MaxPooling2D(pool_size=(2, 2)))
#model.add(Dropout(0.3))
 
#model.add(Conv2D(128, (4, 4)))
#model.add(Activation('relu'))
#model.add(MaxPooling2D(pool_size=(2, 2)))
#model.add(Dropout(0.2))
 
## Flatten convolutional output as required for Dense layers
model.add(Flatten())

## Dense layer
model.add(Dense(144))
model.add(Activation('relu'))
 
## Output dense layer 
model.add(Dense(1))
model.add(Activation('sigmoid'))
 
## Compile the model 
model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'],
              )

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3,restore_best_weights= True)

## Fit the model for the dataset
history = model.fit(features_train, mask_train, 
          batch_size=32,
          epochs=30,
          validation_data=(features_valid,mask_valid),
          callbacks = [es])

# plot training history
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.legend()
plt.show()

#Specify your local drive location to save the model
model.save("drive/My Drive/Colab_Notebooks/Trained_model.h5")

#To load the model into the environment back again, In our case the trained model already provided

import tensorflow as tf
model_l = tf.keras.models.load_model("drive/My Drive/Colab_Notebooks/Trained_model.h5")

"""## Model evaluation"""

#Predict from the model
results = model_l.predict(features_valid)
results = results.ravel()
results_1 = results
results[results>0.51] = 1
results[results<=0.51] = 0

## Reshape mask signal
mask_valid_v1 = mask_valid.ravel()

import pandas as pd
y_actu = pd.Series(mask_valid_v1, name='Actual')
y_pred = pd.Series(results, name='Predicted')
df_confusion = pd.crosstab(y_actu, y_pred,normalize=True)

print(df_confusion)

from sklearn import metrics
fpr, tpr, _ = metrics.roc_curve(y_actu,  y_pred)
auc = metrics.roc_auc_score(y_actu, y_pred)
plt.figure(figsize = (5,5))
plt.plot(fpr,tpr,label="AUC= "+str(np.round(auc,2)))
plt.title("ROC Curve")
plt.plot(fpr,fpr, label = "Random Chance")
plt.legend(loc=4)
plt.show("ROC Curve")

"""## Generating mask signal"""

frame_size = int(0.1*22050)

index1 = 0
index2 = frame_size

mask = np.array([[int(results[0])] * frame_size])

for index in range(1,len(results)):
  index1 = index2
  index2 += frame_size
  
  print(index,end = "\r")
  x = np.array([[int(results[index])] * frame_size])
  
  mask = np.concatenate([mask, x])
  pass

mask = mask.ravel()

"""## Multiply mask generated with signal_valid"""

## Multiply generated mask signal with validation speech signal saved earlier
signal_voice = signal_valid * mask[0:len(signal_valid)]

## Write generated signal to working directory
librosa.output.write_wav("drive/My Drive/Colab_Notebooks/speech_signal_from_CNN.wav",np.float32(emphasized_signal),fs)